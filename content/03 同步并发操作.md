## 等待一个事件或其他条件
* 一个线程要等待另一个线程完成任务，确定完成任务的方法有几种。第一种是持续检查mutex，这种方法显然很浪费资源。第二种是每隔一段时间进行一次检查
```cpp
bool flag;
std::mutex m;

void f()
{
    std::unique_lock<std::mutex> l(m);
    while(!flag)
    {
        l.unlock();
        std::this_thread::sleep_for(std::chrono::milliseconds(100)); // 休眠100ms
        // 休眠期间其他线程就有机会获取mutex并设置flag
        l.lock();
    }
}
```
* 但很难确定适当的休眠时间，过长（会直接影响程序行为，很少见）过短（相当于没有，一样浪费资源）都不好
* 第三种方案是使用条件变量（condition variable），标准库对条件变量提供了两种实现：[std::condition_variable](https://en.cppreference.com/w/cpp/thread/condition_variable)和[std::condition_variable_any](https://en.cppreference.com/w/cpp/thread/condition_variable_any)，前者仅限和[std::mutex](https://en.cppreference.com/w/cpp/thread/mutex)工作，而后者可以与任何满足最低标准的mutex工作（因此加上_any的后缀），更通用也意味着更大的开销，因此一般首选使用前者
```cpp
#include <iostream>
#include <string>
#include <thread>
#include <mutex>
#include <condition_variable>

std::mutex m;
std::condition_variable cv;
std::string data;
bool ready = false;
bool processed = false;

void f()
{
    std::unique_lock<std::mutex> l(m); // 传给wait的只能是std::unique_lock
    cv.wait(l, [] { return ready; }); // 第二个参数为false时解锁mutex阻塞线程
    // 当收到其他线程notify_one时wait会被唤醒，重新检查条件
    data += " after processing";
    processed = true;
    l.unlock();
    cv.notify_one();
}

int main()
{
    std::thread t(f);
    data = "data";
    {
        std::lock_guard<std::mutex> l(m);
        data += " ready";
        ready = true;
        cv.notify_one(); // 唤醒cv.wait，重新检查ready == true
    }
    {
        std::unique_lock<std::mutex> l(m);
        cv.wait(l, [] { return processed; });
    }
    std::cout << data; // data ready after processing
    t.join();
}
```

## 用条件变量实现线程安全的queue
* [std::queue](https://en.cppreference.com/w/cpp/container/queue)的接口如下
```cpp
template<class T, class Container = std::deque<T>>
class queue {
public:
    explicit queue(const Container&);
    explicit queue(Container&&);
    template<class Alloc> explicit queue(const Alloc&);
    template<class Alloc> explicit queue(const  Container&, const Alloc&);
    template<class Alloc> explicit queue(Container&&, const Alloc&);
    template<class Alloc> explicit queue(const queue&, const Alloc&);
    template<class Alloc> explicit queue(queue&&, const Alloc&);
    
    T& front();
    const T& front() const;
    T& back();
    const T& back() const;
    
    bool empty() const;
    size_type size() const;
    
    void swap(queue&);
    void push(const T&);
    void push(T&&);
    void pop();
    template <class... Args> void emplace(Args&&... args);
};
```
* 和[std::stack](https://en.cppreference.com/w/cpp/container/stack)一样，[std::queue](https://en.cppreference.com/w/cpp/container/queue)的接口设计存在固有竞争，因此需要将front和pop合并成一个函数（就像合并[std::stack](https://en.cppreference.com/w/cpp/container/stack)的top和pop）。这里提供了pop的两个变种，try_pop总会直接返回（即使没有可弹出的值），wait_and_pop等待有值可检索才返回。用之前实现stack的方式实现queue，接口就会像下面这样
```cpp
template<typename T>
class A {
public:
    A();
    A(const A&);
    A& operator=(const A&) = delete;
    
    void push(T);
    bool try_pop(T&); // 没有可检索的值则返回false
    std::shared_ptr<T> try_pop(); // 直接返回检索值，没有则返回空指针
    
    void wait_and_pop(T&);
    std::shared_ptr<T> wait_and_pop();
    bool empty() const;
};
```
* 使用条件变量完整实现线程安全的queue
```cpp
#include <memory>
#include <mutex>
#include <condition_variable>
#include <queue>

template<typename T>
class A {
    mutable std::mutex m; // 必须可变
    std::queue<T> q;
    std::condition_variable cv;
public:
    A() {}
    A(const A& rhs)
    {
        std::lock_guard<std::mutex> l(rhs.m);
        q = rhs.q;
    }
    
    void push(T x)
    {
        std::lock_guard<std::mutex> l(m);
        q.push(std::move(x));
        cv.notify_one();
    }
    
    void wait_and_pop(T& x)
    {
        std::unique_lock<std::mutex> l(m);
        cv.wait(l, [this] { return !q.empty(); });
        x = std::move(q.front());
        q.pop();
    }
    
    std::shared_ptr<T> wait_and_pop()
    {
        std::unique_lock<std::mutex> l(m);
        cv.wait(l, [this] { return !q.empty(); });
        std::shared_ptr<T> res(std::make_shared<T>(std::move(q.front())));
        q.pop();
        return res;
    }
    
    bool try_pop(T& x)
    {
        std::lock_guard<std::mutex> l(m);
        if(q.empty()) return false;
        x = std::move(q.front());
        q.pop();
        return true;
    }
    
    std::shared_ptr<T> try_pop()
    {
        std::lock_guard<std::mutex> l(m);
        if(q.empty()) return std::shared_ptr<T>();
        std::shared_ptr<T> res(std::make_shared<T>(std::move(q.front())));
        q.pop();
        return res;
    }
    
    bool empty() const
    {
        std::lock_guard<std::mutex> l(m);
        // 其他线程可能有此对象（拷贝构造）所以要上锁
        return q.empty();
    }
};
```

## 使用期值等待一次性事件
* 标准库提供了只能关联一个事件的唯一期值[std::future](https://en.cppreference.com/w/cpp/thread/future)和能关联多个事件的共享期值[std::shared_future](https://en.cppreference.com/w/cpp/thread/shared_future)，[并发TS](https://en.cppreference.com/w/cpp/experimental/concurrency)中扩展了这两个类，分别为[std::experimental::future](https://en.cppreference.com/w/cpp/experimental/future)和[std::experimental::shared_future](https://en.cppreference.com/w/cpp/experimental/shared_future)
* 最简单的一次性事件就是运行在后台的计算结果，而[std::thread](https://en.cppreference.com/w/cpp/thread/thread)不能获取返回值
```cpp
int f()
{
    return 1;
}

int main()
{
    std::thread t(f); // 如何读取f的返回值？
    t.join();
}
```

### [std::async](https://en.cppreference.com/w/cpp/thread/async)
* 先用[std::async](https://en.cppreference.com/w/cpp/thread/async)启动一个异步任务，它返回一个持有计算结果的[std::future](https://en.cppreference.com/w/cpp/thread/future)，通过[std::future::get](https://en.cppreference.com/w/cpp/thread/future/get)即可阻塞线程，直到期值的状态为ready并返回该结果
```cpp
int f()
{
    return 1;
}

int main()
{
    std::future<int> ft = std::async(f);
    std::cout << ft.get(); // 1
}
```
* [std::async](https://en.cppreference.com/w/cpp/thread/async)和[std::thread](https://en.cppreference.com/w/cpp/thread/thread)一样支持额外的函数参数
```cpp
// 函数
int f(int);
auto ft = std::async(f, 42);

// 成员函数
struct A {
    int f(int);
};

A a;
auto ft1 = std::async(&A::f, &a, 42); // 调用p->f(42)，p是指向x的指针
auto ft2 = std::async(&A::f, a, 42); // 调用tmpa.f(42)，tmpa是a的副本

// 函数对象
struct A {
    int operator()(int);
};
A a;
auto ft1 = std::async(A(), 42); // 调用tmpa(42)，tmpa由A的移动构造函数获得
auto ft2 = std::async(std::ref(a), 42); // 调用a(42)
```
* [std::async](https://en.cppreference.com/w/cpp/thread/async)还可以设置第一个参数为线程的创建策略
```cpp
int f();
// 函数必须异步执行，即运行在不同的线程上
auto ft1 = std::async(std::launch::async, f);
// 函数只在返回的期值调用get或wait时运行
auto ft2 = std::async(std::launch::deferred, f);
// 不指定时的默认启动策略是对两者进行或运算的结果
// auto ft3 = std::async(f)等价于
auto ft3 = std::async(std::launch::async | std::launch::deferred, f);
```

### [std::packaged_task](https://en.cppreference.com/w/cpp/thread/packaged_task)
* 除了[std::async](https://en.cppreference.com/w/cpp/thread/async)，还可以用[std::packaged_task](https://en.cppreference.com/w/cpp/thread/packaged_task)让[std::future](https://en.cppreference.com/w/cpp/thread/future)与任务关联
```cpp
int f();

std::packaged_task<int()> pt(f);
auto ft = pt.get_future();
p(); // 调用std::packaged_task对象，将std::future设为就绪
std::cout << ft.get();
```
* 很多GUI架构要求用指定线程更新GUI，如果另一个线程要更新GUI，就需要发送信消息给指定线程。使用[std::packaged_task](https://en.cppreference.com/w/cpp/thread/packaged_task)即可实现此功能
```cpp
std::mutex m;
std::deque<std::packaged_task<void()>> d;

void gui_thread() // 更新GUI的指定线程
{
    while(!gui_shutdown_message_received()) // 未收到终止消息则一直轮询
    {
        process_gui_message(); // 处理收到的消息
        std::packaged_task<void()> pt;
        {
            std::lock_guard<std::mutex> l(m);
            if(d.empty()) continue; // 进入下一次循环
            pt = std::move(d.front());
            d.pop_front();
        }
        pt();
    }
}

std::thread t(gui_thread);

template<typename F>
std::future<void> postTask(F f)
{
    std::packaged_task<void()> pt(f);
    std::future<void> res = pt.get_future();
    std::lock_guard<std::mutex> l(m);
    d.push_back(std::move(pt));
    return res;
}
```

### [std::promise](https://en.cppreference.com/w/cpp/thread/promise)
* [std::promise](https://en.cppreference.com/w/cpp/thread/promise)可以显式设置值
```cpp
std::promise<int> ps;
std::future<int> ft = ps.get_future();
ps.set_value(42); // set_value还会将状态设置为就绪
std::cout << ft.get(); // 42
```
* 在线程间对状态发送信号
```cpp
void f(std::promise<void> ps)
{
    std::this_thread::sleep_for(std::chrono::seconds(1));
    ps.set_value();
}

int main()
{
    std::promise<void> ps;
    std::future<void> ft = ps.get_future();
    std::thread t(f, std::move(ps));
    ft.wait(); // 阻塞直到set_value，相当于没有返回值的get
    t.join();
}
```
* 一个[std::promise](https://en.cppreference.com/w/cpp/thread/promise)只能关联一个[std::future](https://en.cppreference.com/w/cpp/thread/future)，关联多次时将抛出[std::future_error](https://en.cppreference.com/w/cpp/thread/future_error)异常
```cpp
std::promise<int> ps;
auto ft1 = ps.get_future();
auto ft2 = ps.get_future(); // 抛出std::future_error异常
```

### 将异常存储于期值中
```cpp
int f(int x)
{
    if(x < 0) throw std::out_of_range("x < 0");
    return 1;
}

int main()
{
    auto ft = std::async(f, -1); // ft将存储异常
    int x = ft.get(); // 抛出已存储的异常
}
```
* [std::promise](https://en.cppreference.com/w/cpp/thread/promise)也支持此功能
```cpp
int main()
{
    std::promise<int> ps;
    auto ft = ps.get_future();
    std::thread t([&ps]
    {
        try
        {
            ps.set_value(f(-1)); // 此时还没有存储异常
        }
        catch(...)
        {
            ps.set_exception(std::current_exception()); // 存储异常
        }
    });
    t.join();
    ft.get(); // 抛出异常
}
```
* 如果[std::packaged_task](https://en.cppreference.com/w/cpp/thread/packaged_task)和[std::promise](https://en.cppreference.com/w/cpp/thread/promise)直到析构都未设置值，[std::future::get](https://en.cppreference.com/w/cpp/thread/future/get)也会抛出[std::future_error](https://en.cppreference.com/w/cpp/thread/future_error)异常
```cpp
int f();

int main()
{
    std::future<int> ft;
    {
        std::packaged_task<int()> pt(f);
        ft = pt.get_future();
        // std::promise<int> ps;
        // ft = ps.get_future();
    }
    ft.get(); // 抛出异常
}
```

### [std::shared_future](https://en.cppreference.com/w/cpp/thread/shared_future)
* [std::future](https://en.cppreference.com/w/cpp/thread/future)调用[get](https://en.cppreference.com/w/cpp/thread/future/get)后就无法再次[get](https://en.cppreference.com/w/cpp/thread/future/get)，也就是说只能获取一次数据，此外还会导致所在线程与其他线程数据不同步。[std::shared_future](https://en.cppreference.com/w/cpp/thread/shared_future)就可以解决此问题
```cpp
std::promise<int> ps;
std::future<int> ft(ps.get_future());
assert(ft.valid());
std::shared_future<int> sf(std::move(ft));
assert(!ft.valid());
assert(sf.valid());
```
* 也可以直接构造
```cpp
std::promise<int> ps;
// std::future隐式转换为std::shared_future
std::shared_future<int> sf(ps.get_future());
```
* 用[std::future::share](https://en.cppreference.com/w/cpp/thread/future/share)可以直接生成[std::shared_future](https://en.cppreference.com/w/cpp/thread/shared_future)，这样就可以直接用auto简化声明[std::shared_future](https://en.cppreference.com/w/cpp/thread/shared_future)
```cpp
std::promise<int> ps;
auto sf = ps.get_future().share();
```
* 每一个[std::shared_future](https://en.cppreference.com/w/cpp/thread/shared_future)对象上返回的结果不同步，为了避免多线程访问同一[std::shared_future](https://en.cppreference.com/w/cpp/thread/shared_future)对象时的数据竞争就必须加锁保护。更好的方法是给每个线程拷贝一个[std::shared_future](https://en.cppreference.com/w/cpp/thread/shared_future)对象，这样就可以安全访问而无需加锁

## 限定等待时间
* 阻塞调用的时间不确定，在一些情况下需要限制等待时间。指定超时的方式有两种，一是指定一段延迟的时间（duration），另一种是指定一个时间点

### 时钟（clock）
* 对于标准库来说，时钟就是时间信息源。具体来说，时钟是提供了四种信息的类
  * 当前时间：如[std::chrono::system_clock::now()](https://en.cppreference.com/w/cpp/chrono/system_clock/now)
  * 表示时间值的类型：[std::chrono::time_point](https://en.cppreference.com/w/cpp/chrono/time_point)
  * 时钟节拍（一个嘀嗒的周期）：一般一秒有25个节拍，一个周期则为[std::ratio\<1, 25\>](https://en.cppreference.com/w/cpp/numeric/ratio/ratio)
  * 通过时钟节拍确定时钟是否稳定（steady，匀速）：[std::chrono::steady_clock::is_steady](https://en.cppreference.com/w/cpp/chrono/steady_clock)（稳定时钟，代表系统时钟的真实时间）、[std::chrono::system_clock::is_steady](https://en.cppreference.com/w/cpp/chrono/system_clock)（一般因为时钟可调节而不稳定，即使这是为了考虑本地时钟偏差的自动调节）、[high_resolution_clock::is_steady](https://en.cppreference.com/w/cpp/chrono/high_resolution_clock)（最小节拍最高精度的时钟）
* 打印当前系统时间（如果出现localtime不安全的警告，则在`配置属性 - C/C++ - 预处理器 - 预处理器定义`添加`_CRT_SECURE_NO_WARNINGS`）
```cpp
std::chrono::system_clock::time_point now = std::chrono::system_clock::now();
std::time_t now_c = std::chrono::system_clock::to_time_t(now); // 转为整数
std::cout << std::put_time(std::localtime(&now_c), "%F %T"); // %F即%Y-%m-%d，%T即%H:%M:%S
```

### [std::chrono::duration](https://en.cppreference.com/w/cpp/chrono/duration)
* 标准库提供了表示时间间隔类型的[std::chrono::duration](https://en.cppreference.com/w/cpp/chrono/duration)
```cpp
// 比如将表示秒的类型定义为
std::duration<int> // 即std::chrono::seconds
// 则表示分的类型可定义为
std::duration<int, std::ratio<60>> // 即std::chrono::minutes
// 表示毫秒的类型可定义为
std::duration<int, std::ratio<1, 1000>> // 即std::chrono::milliseconds
```
* C++14的[std::chrono_literals](https://en.cppreference.com/w/cpp/language/user_literal%23Standard_library)提供了表示时间的后缀
```cpp
using namespace std::chrono_literals;
auto x = 45min; // 等价于std::chrono::minutes(45)
std::cout << x.count(); // 45
auto y = std::chrono::duration_cast<std::chrono::seconds>(x);
std::cout << y.count(); // 2700
auto z = std::chrono::duration_cast<std::chrono::hours>(x);
std::cout << z.count(); // 0（转换会截断）
```
* 标准库通过字面值运算符模板实现此后缀功能
```cpp
constexpr std::chrono::minutes operator ""min(unsigned long long m)
{
    return std::chrono::minutes(m);
}
```
* duration支持四则运算
```cpp
using namespace std::chrono_literals;
auto x = 1h;
auto y = 15min;
auto z = x - 2 * y;
std::cout << z.count(); // 30
```
* 使用duration即可设置等待时间
```cpp
int f();
auto ft = std::async(f);

using namespace std::chrono_literals;
if(ft.wait_for(1s) == std::future_status::ready)
{
    std::cout << ft.get();
}
```

### [std::chrono::time_point](https://en.cppreference.com/w/cpp/chrono/time_point)
* time_point是表示时间的类型，值为从某个时间点（比如unix时间戳：1970年1月1日0时0分）开始计时的时间长度
```cpp
// 第一个模板参数为开始时间点的时钟类型，第二个为时间单位
std::chrono::time_point<std::chrono::system_clock, std::chrono::seconds>
```
* time_point可以加减dutation
```cpp
using namespace std::chrono_literals;
auto x = std::chrono::high_resolution_clock::now();
auto y = x + 1s;
std::cout << std::chrono::duration_cast<std::chrono::milliseconds>(y - x).count();
```
* 两个time_point也能相减
```cpp
auto start = std::chrono::high_resolution_clock::now();
doSomething();
auto stop = std::chrono::high_resolution_clock::now();
std::cout << std::chrono::duration_cast<std::chrono::milliseconds>(stop - start).count();
```
* 使用绝对的时间点来设置等待时间
```cpp
std::condition_variable cv;
bool done;
std::mutex m;

bool wait_loop()
{
    const auto timeout = std::chrono::steady_clock::now() + std::chrono::milliseconds(500);
    std::unique_lock<std::mutex> l(m);
    while(!done)
    {
        if(cv.wait_until(l, timeout) == std::cv_status::timeout) break;
    }
    return done;
}
```

### 接受timeout的函数
* timeout可以用于休眠，比如[std::this_thread::sleep_for](https://en.cppreference.com/w/cpp/thread/sleep_for)和[std::this_thread::sleep_until](https://en.cppreference.com/w/cpp/thread/sleep_until)，此外timeout还能配合条件变量、期值甚至mutex使用。[std::mutex](https://en.cppreference.com/w/cpp/thread/mutex)和[std::recursive_mutex](https://en.cppreference.com/w/cpp/thread/recursive_mutex)不支持timeout，而[std::timed_mutex](https://en.cppreference.com/w/cpp/thread/timed_mutex)和[std::recursive_timed_mutex](https://en.cppreference.com/w/cpp/thread/recursive_timed_mutex)支持，它们提供了[try_lock_for](https://en.cppreference.com/w/cpp/thread/timed_mutex/try_lock_for)和[try_lock_until](https://en.cppreference.com/w/cpp/thread/timed_mutex/try_lock_until)
* 支持timeout的函数有
  * [std::this_thread::sleep_for](https://en.cppreference.com/w/cpp/thread/sleep_for)
  * [std::this_thread::sleep_until](https://en.cppreference.com/w/cpp/thread/sleep_until)
  * [std::condition_variable::wait_for](https://en.cppreference.com/w/cpp/thread/condition_variable/wait_for)
  * [std::condition_variable::wait_until](https://en.cppreference.com/w/cpp/thread/condition_variable/wait_until)
  * [std::condition_variable_any::wait_for](https://en.cppreference.com/w/cpp/thread/condition_variable_any/wait_for)
  * [std::condition_variable_any::wait_until](https://en.cppreference.com/w/cpp/thread/condition_variable_any/wait_until)
  * [std::timed_mutex::try_lock_for](https://en.cppreference.com/w/cpp/thread/timed_mutex/try_lock_for)
  * [std::timed_mutex::try_lock_until](https://en.cppreference.com/w/cpp/thread/timed_mutex/try_lock_until)
  * [std::recursive_timed_mutex::try_lock_for](https://en.cppreference.com/w/cpp/thread/recursive_timed_mutex/try_lock_for)
  * [std::recursive_timed_mutex::try_lock_until](https://en.cppreference.com/w/cpp/thread/recursive_timed_mutex/try_lock_until)
  * [std::unique_lock::try_lock_for](https://en.cppreference.com/w/cpp/thread/unique_lock/try_lock_for)
  * [std::unique_lock::try_lock_until](https://en.cppreference.com/w/cpp/thread/unique_lock/try_lock_until)
  * [std::future::wait_for](https://en.cppreference.com/w/cpp/thread/future/wait_for)
  * [std::future::wait_until](https://en.cppreference.com/w/cpp/thread/future/wait_until)
  * [std::shared_future::wait_for](https://en.cppreference.com/w/cpp/thread/shared_future/wait_for)
  * [std::shared_future::wait_until](https://en.cppreference.com/w/cpp/thread/shared_future/wait_until)

## 使用同步操作简化代码

### 使用期值进行函数式编程（functional programming）
* FP不会改变外部状态，不修改共享数据就不存在race condition，因此也就没有必要使用锁
* 以快速排序为例

![](../images/3-1.png)

* 快速排序的顺序实现（虽然接口是函数式，但考虑到FP实现需要大量拷贝操作，所以内部使用命令式）
```cpp
template<typename T>
std::list<T> f(std::list<T> v)
{
    if(v.empty()) return v;
    std::list<T> res;
    // std::list::splice用于转移另一个list中的元素到目标list
    res.splice(res.begin(), v, v.begin()); // 将v的首元素移到res中
    const T& firstVal = *res.begin();
    // std::partition按条件在原容器上划分为两部分
    // 并返回划分点（第一个不满足条件元素）的迭代器
    auto it = std::partition(v.begin(), v.end(), [&](const T& x) { return x < firstVal; });
    std::list<T> low;
    low.splice(low.end(), v, v.begin(), it); // 转移左半部分到low
    auto l(f(std::move(low))); // 对左半部分递归排序
    auto r(f(std::move(v))); // 对右半部分递归排序
    res.splice(res.end(), r);
    res.splice(res.begin(), l);
    return res;
}
```
* 使用期值实现并行的快速排序
```cpp
template<typename T>
std::list<T> f(std::list<T> v)
{
    if(v.empty()) return v;
    std::list<T> res;
    res.splice(res.begin(), v, v.begin());
    const T& firstVal = *res.begin();
    auto it = std::partition(v.begin(), v.end(), [&](const T& x) { return x < firstVal; });
    std::list<T> low;
    low.splice(low.end(), v, v.begin(), it);
    // 用另一个线程对左半部分排序
    std::future<std::list<T>> l(std::async(&f<T>, std::move(low)));
    // 其他不变
    auto r(f(std::move(v)));
    res.splice(res.end(), r);
    res.splice(res.begin(), l.get()); // 获取future中的值
    return res;
}
```
* FP不仅是并发编程的典范，还是CSP（Communicating Sequential Processer）的典范。CSP中的线程理论上是分开的，没有共享数据，但communication channel允许消息在不同线程间传递，这被Erlang所采用，并在MPI（Message Passing Interface）上常用来做C和C++的高性能计算

### 使用消息传递进行同步操作
* CSP的思路很简单，如果没有共享数据，每个线程可以完全独立地思考，其行为取决于收到的消息。因此每个线程实际上是一个状态机，收到一条消息时就以某种方式更新状态，并且还可能发送消息给其他线程
* 真正的CSP没有共享数据，所有通信通过消息队列传递，但由于C++线程共享地址空间，因此无法强制实现这个要求。所以这就需要引入一些约定，作为应用或者库的作者，必须确保在线程间不会共享数据（当然为了通信，必须共享消息队列）
* 考虑实现一个ATM应用，它需要处理取钱时和银行的交互，并控制物理机器对银行卡的反应。一个处理方法是分三个线程，分别处理物理机器、ATM逻辑、与银行的交互，线程间通过消息通讯而非共享数据，比如插卡时机器线程发送消息给逻辑线程，逻辑线程返回一条消息通知机器线程可以给多少钱
* 一个简单的ATM逻辑的状态机建模如下

![](../images/3-2.png)

* 这个状态机可以用一个类实现，类中有一个表示状态的成员函数
```cpp
struct card_inserted
{
    std::string account;
};

class atm
{
    messaging::receiver incoming;
    messaging::sender bank;
    messaging::sender interface_hardware;
    void (atm::*state)();
    std::string account;
    std::string pin;
    
    void waiting_for_card()
    {
        interface_hardware.send(display_enter_card());
        incoming.wait()
        .handle<card_inserted>([&](const card_inserted& msg)
        {
            account = msg.account;
            pin = "";
            interface_hardware.send(display_enter_pin());
            state = &atm::getting_pin;
        });
    }
    
    void getting_pin();
public:
    void run()
    {
        state = &atm::waiting_for_card;
        try
        {
            for(;;) (this->*state)();
        }
        catch(const messaging::close_queue&) {}
    }
};
```
* getting_pin的实现比较繁琐，它要处理三种不同的消息
```cpp
void atm::getting_pin()
{
    incoming.wait()
    .handle<digit_pressed>([&](const digit_pressed& msg)
    {
        const unsigned pin_length = 4;
        pin += msg.digit;
        if(pin.length() == pin_length)
        {
            bank.send(verify_pin(account, pin, incoming));
            state = &atm::verifying_pin;
        }
    })
    .handle<clear_last_pressed>([&](const clear_last_pressed& msg)
    {
        if(!pin.empty()) pin.resize(pin.length() - 1);
    })
    .handle<cancel_pressed>([&](const cancel_pressed& msg)
    {
        state = &atm::done_processing;
    });
}
```
* 这里不需要考虑同步和并发的问题，只要考虑在某个点接受和发送的消息。这个ATM逻辑的状态机与系统的其他部分各自运行在独立的线程上，这种设计方式称为actor model，系统中有多个独立的actor，actor之间可以互相发送消息但不会共享状态，这种方式可以极大简化并发系统的设计
* 完整的代码实现[见此](../code/ATM完整示例.cpp)，VS2017编译出错，在[C++ Shell](http://cpp.sh/)上能编译成功

### [std::experimental::future](https://en.cppreference.com/w/cpp/experimental/future)
* [并发TS](https://en.cppreference.com/w/cpp/experimental/concurrency)中提供了[std::experimental::promise](https://en.cppreference.com/w/cpp/experimental/concurrency/promise)和[std::experimental::packaged_task](https://en.cppreference.com/w/cpp/experimental/concurrency/packaged_task)，与标准库唯一不同的是，它们返回[std::experimental::future](https://en.cppreference.com/w/cpp/experimental/future)，这个期值提供了持续性
* 需要处理[std::future](https://en.cppreference.com/w/cpp/thread/future)的结果时，必须等待其调用成员函数，这很不方便。持续性带来的好处是数据就绪就（then）进行处理，调用[std::experimental::future::then](https://en.cppreference.com/w/cpp/experimental/future/then)即可添加持续性
```cpp
int f(std::experimental::future<int>);

std::experimental::future<int> eft;
auto ft1 = eft(); // std::experimental::future由本身的构造函数生成
// 添加持续性并返回新的期值，该期值持有持续性调用的结果
// 与std::async不同，不能传入f的参数
// 因为参数已经在运行库中定义为了一个就绪的期值
// 这里f的返回int，因此参数就是std::experimental::future<int>
auto ft2 = ft1.then(f);
// then后原期值就无效了
assert(!ft1.valid());
assert(ft2.valid());
```
* [std::async](https://en.cppreference.com/w/cpp/thread/async)只能返回[std::future](https://en.cppreference.com/w/cpp/thread/future)，如果想返回[std::experimental::future](https://en.cppreference.com/w/cpp/experimental/future)则需要手动实现一个新的async
```cpp
template<typename F>
std::experimental::future<decltype(std::declval<F>()())>
new_async(F&& func)
{
    std::experimental::promise<decltype(std::declval<F>()())> p;
    auto ft = p.get_future();
    std::thread t(
        [p = std::move(p), f = std::decay_t<F>(func)]() mutable {
            try {
                p.set_value_at_thread_exit(f());
            } catch(...) {
                p.set_exception_at_thread_exit(std::current_exception());
            }
        }
    );
    t.detach();
    return ft;
}
```
* 假如要实现一个登录逻辑，将用户名和密码发送给后台验证，取得用户信息后更新到显示界面，串行实现如下
```cpp
void process_login(const std::string& username, const std::string& password)
{
    try {
        const user_id id = backend.authenticate_user(username, password);
        const user_data info_to_display = backend.request_current_info(id);
        update_display(info_to_display);
    } catch(std::exception& e) {
        display_error(e);
    }
}
```
* 为了不阻塞UI线程，就需要异步实现
```cpp
std::future<void> process_login(const std::string& username, const std::string& password)
{
    return std::async(std::launch::async, [=] () {
        try {
            const user_id id = backend.authenticate_user(username, password);
            const user_data info_to_display = backend.request_current_info(id);
            update_display(info_to_display);
        } catch(std::exception& e) {
            display_error(e);
        }
    });
}
```
* 但这个实现仍然会阻塞UI线程，为此就需要持续性的机制，每个任务完成后连接到前一个任务上
```cpp
std::experimental::future<void> process_login(const std::string& username, const std::string& password)
{
    return new_async([=] () {
        return backend.authenticate_user(username, password);
    })
    .then([] (std::experimental::future<user_id> id) {
        return backend.request_current_info(id.get());
    })
    .then([] (std::experimental::future<user_data> info_to_display) {
        try {
            update_display(info_to_display.get());
        } catch(std::exception& e) {
            display_error(e);
        }
    });
}
```
* 如果调用后台函数内部阻塞，可能是因为需要等待消息通过网络或者完成一个数据库操作，而你还没有完成这些。你可能会把任务划分为多个独立部分，但它们仍会阻塞调用，最终仍会得到阻塞的线程。这时后台调用真正需要的是在数据准备好时返回就绪的期值，而不阻塞任何线程，所以这里用返回`std::experimental::future<user_id>`的`backend.async_authenticate_user`替代返回`user_id`的`backend.authenticate_user`
```cpp
std::experimental::future<void> process_login(const std::string& username, const std::string& password)
{
    return backend.async_authenticate_user(username, password)
    .then([] (std::experimental::future<user_id> id) {
        return backend.async_request_current_info(id.get());
    })
    .then([] (std::experimental::future<user_data> info_to_display) {
        try {
            update_display(info_to_display.get());
        } catch(std::exception& e) {
            display_error(e);
        }
    });
}
```
* 这样就是在异步函数链上就不存在阻塞了。最后这里还可以用泛型lambda来简化代码
```cpp
std::experimental::future<void> process_login(const std::string& username, const std::string& password)
{
    return backend.async_authenticate_user(username, password)
    .then([] (auto id) {
        return backend.async_request_current_info(id.get());
    })
    .then([] (auto info_to_display) {
        try {
            update_display(info_to_display.get());
        } catch(std::exception& e) {
            display_error(e);
        }
    });
}
```
* 除了[std::experimental::future](https://en.cppreference.com/w/cpp/experimental/future)，支持持续性的还有 [std::experimental::shared_future](https://en.cppreference.com/w/cpp/experimental/shared_future)
```cpp
auto ft1 = new_async(some_function).share();
auto ft2 = ft1.then([] (std::experimental::shared_future<some_data> data) {
    do_stuff(data);
});
auto ft3 = ft1.then([] (std::experimental::shared_future<some_data> data) {
    return do_other_stuff(data);
});
```

### [std::experimental::when_all](https://en.cppreference.com/w/cpp/experimental/when_all)
* 使用std::async从多个期值中获取结果
```cpp
std::future<FinalResult> process_data(std::vector<MyData>& vec)
{
    const size_t chunk_size = whatever;
    std::vector<std::future<ChunkResult>> res;
    for(auto begin = vec.begin(), end = vec.end(); beg! = end;)
    {
        const size_t remaining_size = end - begin;
        const size_t this_chunk_size = std::min(remaining_size, chunk_size);
        res.push_back(std::async(process_chunk, begin, begin + this_chunk_size));
        begin += this_chunk_size;
    }
    return std::async([all_results = std::move(res)] () {
        std::vector<ChunkResult> v;
        v.reserve(all_results.size());
        for(auto& f: all_results)
        {
            v.push_back(f.get()); // 这里会导致反复唤醒，增加了很多开销
        }
        return gather_results(v);
    });
}
```
* 使用[std::experimental::when_all](https://en.cppreference.com/w/cpp/experimental/when_all)可以避免反复唤醒导致的开销，为其传入一组需要等待的期值，将返回一个新的期值。当传入的所有期值都就绪时，则返回的期值就绪
```cpp
std::experimental::future<FinalResult> process_data(std::vector<MyData>& vec)
{
    const size_t chunk_size = whatever;
    std::vector<std::experimental::future<ChunkResult>> res;
    for(auto begin = vec.begin(), end = vec.end(); beg! = end;)
    {
        const size_t remaining_size = end - begin;
        const size_t this_chunk_size = std::min(remaining_size, chunk_size);
        res.push_back(new_async(process_chunk, begin, begin + this_chunk_size));
        begin += this_chunk_size;
    }
    return std::experimental::when_all(res.begin(), res.end())
    .then([] (std::future<std::vector<std::experimental::future<ChunkResult>>> ready_results)
    {
        std::vector<std::experimental::future<ChunkResult>>
        all_results = ready_results.get();
        std::vector<ChunkResult> v;
        v.reserve(all_results.size());
        for(auto& f: all_results)
        {
            v.push_back(f.get());
        }
        return gather_results(v);
    });
}
```

### [std::experimental::when_any](https://en.cppreference.com/w/cpp/experimental/when_any)
* 在传入的期值中有一个就绪时，则[std::experimental::when_any](https://en.cppreference.com/w/cpp/experimental/when_any)返回的期值就绪
```cpp
std::experimental::future<FinalResult>
find_and_process_value(std::vector<MyData>& data)
{
    const unsigned concurrency = std::thread::hardware_concurrency();
    const unsigned num_tasks = (concurrency > 0) ? concurrency : 2;
    std::vector<std::experimental::future<MyData*>> res;
    const auto chunk_size = (data.size() + num_tasks - 1) / num_tasks;
    auto chunk_begin = data.begin();
    std::shared_ptr<std::atomic<bool>> done_flag = std::make_shared<std::atomic<bool>>(false);
    for(unsigned i = 0; i < num_tasks; ++i)
    { // 产生num_tasks个异步任务到res中
        auto chunk_end = (i < (num_tasks - 1)) ? chunk_begin + chunk_size : data.end();
        res.push_back(new_async([=] {
            for(auto entry = chunk_begin; !*done_flag && (entry != chunk_end); ++entry)
            {
                if(matches_find_criteria(*entry))
                {
                    *done_flag = true;
                    return &*entry;
                }
            }
            return (MyData**)nullptr;
        }));
        chunk_begin = chunk_end;
    }
    std::shared_ptr<std::experimental::promise<FinalResult>> final_result =
        std::make_shared<std::experimental::promise<FinalResult>>();

    struct DoneCheck {
        std::shared_ptr<std::experimental::promise<FinalResult>> final_result;
        
        DoneCheck(std::shared_ptr<std::experimental::promise<FinalResult>> final_result_)
        : final_result(std::move(final_result_)) {}
        
        void operator()(
            std::experimental::future<std::experimental::when_any_result<
                std::vector<std::experimental::future<MyData*>>>> res_param)
        {
            auto res = res_param.get();
            MyData* const ready_result = res.futures[res.index].get(); // 从就绪的期值中获取值
            // 找到符合条件的值则处理结果并set_value
            if(ready_result) final_result->set_value(process_found_value(*ready_result));
            else {
                res.futures.erase(res.futures.begin() + res.index); // 否则丢弃值
                if(!res.futures.empty()) { // 如果还有需要检查的值则再次调用when_any
                    std::experimental::when_any(res.futures.begin(), res.futures.end())
                    .then(std::move(*this));
                } else { // 如果没有其他期值则在promise中设置一个异常
                    final_result->set_exception(std::make_exception_ptr(std::runtime_error("Not found")));
                }
            }
        }
    };
    std::experimental::when_any(res.begin(), res.end()).then(DoneCheck(final_result));
    return final_result->get_future();
}
```
* when_all和when_any除了可以接收一对迭代器，也可以直接接受期值
```cpp
std::experimental::future<int> ft1 = new_async(f1);
std::experimental::future<std::string> ft2 = new_async(f2);
std::experimental::future<double> ft3 = new_async(f3);
std::experimental::future<
    std::tuple<
        std::experimental::future<int>,
        std::experimental::future<std::string>,
        std::experimental::future<double>>> res =
    std::experimental::when_all(std::move(ft1), std::move(ft2), std::move(ft3));
```

### [std::experimental::latch](https://en.cppreference.com/w/cpp/experimental/latch)
* [std::experimental::latch](https://en.cppreference.com/w/cpp/experimental/latch)用一个计数器值构造，等待事件发生时就调用[std::experimental::latch::count_down](https://en.cppreference.com/w/cpp/experimental/latch/count_down)将计数器值减一，计数器值为0时则[std::experimental::latch::is_ready](https://en.cppreference.com/w/cpp/experimental/latch/is_ready)返回true，如果想让计数器减一并阻塞至0则可以调用[std::experimental::latch::count_down_and_wait](https://en.cppreference.com/w/cpp/experimental/latch/count_down_and_wait)
* 用[std::experimental::latch](https://en.cppreference.com/w/cpp/experimental/latch)等待事件
```cpp
void f()
{
    const unsigned thread_count = ...;
    std::experimental::latch done(thread_count); // 用计数器值构造latch
    my_data data[thread_count];
    std::vector<std::future<void>> threads;
    for(unsigned i = 0; i < thread_count; ++i)
    {
        threads.push_back(std::async(std::launch::async, [&, i] {
            data[i] = make_data(i);
            done.count_down(); // 在进行下一步之前先递减计数器
            do_more_stuff();
        }));
    }
    done.wait(); // 等待至计数器为0
    process_data(data, thread_count);
}
```

### [std::experimental::barrier](https://en.cppreference.com/w/cpp/experimental/barrier)
* 一组处理数据的线程，处理过程中独立，无需同步，但在处理下一项数据前，必须要求所有线程完成任务。[std::experimental::barrier](https://en.cppreference.com/w/cpp/experimental/barrier)就可以用于处理这种情况，它用线程的数量构造，调用[std::experimental::barrier::arrive_and_wait](https://en.cppreference.com/w/cpp/experimental/barrier/arrive_and_wait)会阻塞至所有线程完成任务，当最后一个线程完成任务时，所有线程被释放，barrier被重置。如果想从线程集中移除线程，可以让该线程在barrier上调用[std::experimental::barrier::arrive_and_drop](https://en.cppreference.com/w/cpp/experimental/barrier/arrive_and_drop)
```cpp
result_chunk process(data_chunk);
std::vector<data_chunk> divide_into_chunks(data_block data, unsigned num_threads);

void process_data(data_source& source, data_sink& sink) // 源数据和输出数据
{
    const unsigned concurrency = std::thread::hardware_concurrency();
    const unsigned num_threads = (concurrency > 0) ? concurrency : 2;
    std::experimental::barrier b(num_threads); // 构造barrier
    std::vector<joining_thread> threads(num_threads);
    std::vector<data_chunk> chunks;
    result_block res;
    for(unsigned i = 0; i < num_threads; ++i)
    {
        threads[i] = joining_thread([&, i] {
            while(!source.done()) // 循环至处理完所有任务
            {
                if(i == 0)
                { // 线程0拆分数据
                    data_block current_block = source.get_next_data_block();
                    chunks = divide_into_chunks(current_block, num_threads);
                }
                b.arrive_and_wait(); // 这里阻塞是因为其他线程必须等待线程0初始化
                res.set_chunk(i, num_threads, process(chunks[i])); // 更新结果到res
                b.arrive_and_wait(); // 这里阻塞是因为写入前线程0必须等待其他线程完成
                if(i == 0) sink.write_data(std::move(res)); // 只有线程0可以输出结果
            }
        });
    }
}
```

### [std::experimental::flex_barrier](https://en.cppreference.com/w/cpp/experimental/flex_barrier)
* [std::experimental::flex_barrier](https://en.cppreference.com/w/cpp/experimental/flex_barrier)比[std::experimental::barrier](https://en.cppreference.com/w/cpp/experimental/barrier)，但开销更大，此外[std::experimental::flex_barrier](https://en.cppreference.com/w/cpp/experimental/flex_barrier)还要多接受一个函数作为参数，当所有线程到达阻塞点时，由其中一个线程运行该函数
* 下面用[std::experimental::flex_barrier](https://en.cppreference.com/w/cpp/experimental/flex_barrier)简化上面的例子
```cpp
void process_data(data_source& source, data_sink& sink)
{
    const unsigned concurrency = std::thread::hardware_concurrency();
    const unsigned num_threads = (concurrency > 0) ? concurrency : 2;
    std::vector<data_chunk> chunks;
    auto split_source = [&] {
        if(!source.done())
        {
            data_block current_block = source.get_next_data_block();
            chunks = divide_into_chunks(current_block, num_threads);
        }
    };
    split_source(); // 先调用上面的lambda拆分数据
    result_block res;
    std::experimental::flex_barrier sync(num_threads, [&] {
        sink.write_data(std::move(res)); // 每次迭代完成输出一次结果
        split_source(); // 并为下一次迭代拆分数据
        return -1; // 必须返回不小于-1的值且不抛出异常，-1表示线程数不变
        // 返回其他值则表示下一周期的线程数
    });
    std::vector<joining_thread> threads(num_threads);
    for(unsigned i = 0; i < num_threads; ++i)
    {
        threads[i] = joining_thread([&, i] {
            while(!source.done())
            {
                res.set_chunk(i, num_threads, process(chunks[i])); // 更新结果到res
                sync.arrive_and_wait(); // 只需要一个阻塞点
            }
        });
    }
}
```
